<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Condy Kan&#39;s Midterm Code Documentation: Main Page</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Condy Kan&#39;s Midterm Code Documentation
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Main Page </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="autotoc_md0"></a>
Contextual Bandit Methods</h1>
<p>We would solve contextual bandit problems, using a policy-gradient based reinforcement learning. We would evaluate seven different epsilon-based strategies. We have Epsilon-Greedy, Epsilon-Decreasing, and five different combinations of Epsilon-Greedy and Epsilon-Decreasing. We tweaked with the epsilon probability and episodes. Five combinations were created!</p>
<p>In the experiment, we have 10,000 episodes and use the learning rate of 0.05. The epsilon is the probability of exploration.</p>
<p><b>Epsilon-Decreasing:</b> The experiment starts with pure exploration and epsilon is decreased to 0% in the end.</p>
<p><b>Epsilon-Greedy:</b> Epsilon is 10%. The probability is fixed.</p>
<p><b>Hybrid#1:</b> Epsilon is decreased from 90% to 10% throughout the experiment.</p>
<p><b>Hybrid#2:</b> Epsilon is decreased from 100% to 10% in the first 5,000 episodes and keeps as 10% for the rest of the experiment.</p>
<p><b>Hybrid#3:</b> Epsilon is decreased from 90% to 10% in the first 5,000 episodes and keeps as 10% for the rest of the experiment.</p>
<p><b>Hybrid#4:</b> Epsilon is decreased from 100% to 10% in the first 2,500 episodes and keeps as 10% for the rest of the experiment.</p>
<p><b>Hybrid#5:</b> Epsilon is decreased from 90% to 10% in the first 2,500 episodes and keeps as 10% for the rest of the experiment.</p>
<p>All of the strategies are in the evaluation code. The reinforcement learning code is derived from <a href="https://www.oreilly.com/library/view/tensorflow-powerful-predictive/9781789136913/">Md. Rezaul Karim</a> and <a href="https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-1-5-contextual-bandits-bff01d1aad9c">Arthur Juliani</a>.</p>
<h2><a class="anchor" id="autotoc_md1"></a>
Table of contents</h2>
<ul>
<li>Requirements</li>
<li>Setup</li>
<li>Instructions</li>
</ul>
<h2><a class="anchor" id="autotoc_md2"></a>
Requirements</h2>
<p>Since all the code are written in Python, you should have or download <a href="https://www.python.org/downloads/">Python</a>.</p>
<p>You will need to have a couple of Python's libraries/packages: numPy, pandas, Tensorflow, matplotlibpyplot, scipy.stats, and atsmodels.stats.multicomp. Most of the packages are pre-installed in Anaconda.</p>
<p>You will be able to run the programs in Anaconda prompt.</p>
<p><em>Note: if you are able to run the programs or have those packages installed in a different software or environment. You can skip the Setup section or (You could install the packages with Pip.)</em></p>
<h2><a class="anchor" id="autotoc_md3"></a>
Setup</h2>
<p>You will be installing <a href="http://anaconda.com/downloads">Anaconda</a> and required packages for this project. Please download the right version for your system/computer.</p>
<p>Recall that numPy, pandas, matplotlibpyplot, and stats packages are already installed in Jupyter notebook, you only need to install TensorFlow 1.14. Using the Anaconda Prompt, it can be done by entering:</p>
<div class="fragment"><div class="line">conda install -c conda-forge tensorflow=1.14</div>
</div><!-- fragment --><p>Note: It depends on your system. There are other commands that you can run with conda. Please read more about <a href="https://anaconda.org/conda-forge/tensorflow">Tensorflow Installment</a>.</p>
<h2><a class="anchor" id="autotoc_md4"></a>
Instructions</h2>
<p>There are two options that you could download the whole code.</p><ol type="1">
<li>Click "Code" green button and "download ZIP" on the top right hand on the repository page.</li>
<li>Clone a repository by performing git clone.</li>
</ol>
<p>Once you have the files in your system/computer, you should see there are three different datasets: <a href="https://github.com/ck2860/MidtermCode-CondyKan/blob/master/data/Ads_Optimisation.csv">Ads Optimisation</a>, <a href="https://github.com/ck2860/MidtermCode-CondyKan/blob/master/data/MeanRewardsResult.csv">Mean Rewards Results</a>, and <a href="https://github.com/ck2860/MidtermCode-CondyKan/blob/master/data/TukeyData.csv">Tukey Data</a>, which are already provided in the data folder. You will be using them for this code project so make sure they are in the right folder &ndash; data. When you run the python scripts, they should be able to find the datasets in the data folder.</p>
<p>The Ads Optimisation data set is obtained from <a href="https://www.kaggle.com/akram24/ads-ctr-optimisation">Kaggle</a>. You will be using this for reinforcement learning and evaluations.</p>
<p>Both Mean Rewards Result and <a class="el" href="namespace_tukey.html">Tukey</a> datasets are the results from the evaluations with 20 random seeds. The Mean Rewards Result data is used for T-tests and ANOVA. Lastly, the <a class="el" href="namespace_tukey.html">Tukey</a> Data is used for <a class="el" href="namespace_tukey.html">Tukey</a> Test.</p>
<p><em>Please make sure they all are in the same directory so the scripts would be able to recognize the data sets from the data folder. For this reinforcement learning, the data set can be used in online advertising to determine which is the best ad to show the user. It does not mean they would work with other bandit problems.</em></p>
<p>You will have five Pythons scripts to run if you like! The figures for evaluations and <a class="el" href="namespace_tukey.html">Tukey</a> should be in pop-up windows. For evaluations, there are three Python program that you can run: <a href="https://github.com/ck2860/MidtermCode-CondyKan/blob/master/1trial.py">1trial.py</a>, <a href="https://github.com/ck2860/MidtermCode-CondyKan/blob/master/10trials.py">10trials.py</a>, and <a href="https://github.com/ck2860/MidtermCode-CondyKan/blob/master/20trials.py">20trials.py</a>. 1trial.py runs one trial of evaluation. 10trials.py runs 10 trials of evaluation. Then 20trials.py runs 20 trials of evaluation. Last two Python programs: <a href="https://github.com/ck2860/MidtermCode-CondyKan/blob/master/StatsTests.py">StatsTests.py</a> and <a href="https://github.com/ck2860/MidtermCode-CondyKan/blob/master/Tukey.py">Tukey.py</a> are used for statistical analysis. You run T-tests and ANOVA by running StatsTest.py. You also can do a <a class="el" href="namespace_tukey.html">Tukey</a> test by compiling Tukey.py. Please read <a href="https://ck2860.github.io/MidtermCode-CondyKan/">documentation</a> for more details.</p>
<p>Please open your Anaconda Prompt and go to the directory where you downloaded the project code.</p>
<p>If you want to run one trial of greedy-based strategies of your chosen random seed. For example, if you want to run it with a random seed of 5. You can compile it by: </p><div class="fragment"><div class="line">python 1trial.py 5</div>
</div><!-- fragment --><p><em>Note that if you use a different random seed for 1trial.py, the evaluation results may be different due to reinforcement learning and strategies.</em></p>
<p>If you want to run 10 trials of greedy-based strategies of your chosen random seed. You should compile it by: </p><div class="fragment"><div class="line">python 10trials.py</div>
</div><!-- fragment --><p>If you want to run 20 trials of greedy-based strategies of your chosen random seed. Your command line should be: </p><div class="fragment"><div class="line">python 20trials.py</div>
</div><!-- fragment --><p>For t-tests and ANOVA, you would want to run by:</p>
<div class="fragment"><div class="line">python StatsTests.py</div>
</div><!-- fragment --><p>Lastly, you can run a <a class="el" href="namespace_tukey.html">Tukey</a> Test by: </p><div class="fragment"><div class="line">python Tukey.py</div>
</div><!-- fragment --><p>If you have any questions, please feel free to email me at <a href="#" onclick="location.href='mai'+'lto:'+'ck2'+'86'+'0@r'+'it'+'.ed'+'u'; return false;">ck286<span style="display: none;">.nosp@m.</span>0@ri<span style="display: none;">.nosp@m.</span>t.edu</a>.</p>
<p>Thanks for reading! </p>
</div></div><!-- PageDoc -->
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.17
</small></address>
</body>
</html>
