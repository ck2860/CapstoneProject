<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Condy Kan's Midterm Code Documentation: Contextual Bandits</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">My Project
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Contextual Bandits </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>We would solve contextual bandit problems, using a policy-gradient based reinforcement learning. We would evaluate three different greedy strategies: Explore-First, Epsilon-Decreasing, and Epsilon-Greedy.</p>
<p>The reinforcement learning code is derived from <a href="https://www.oreilly.com/library/view/tensorflow-powerful-predictive/9781789136913/">Md. Rezaul Karim</a> and <a href="https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-1-5-contextual-bandits-bff01d1aad9c">Arthur Juliani</a>.</p>
<h1><a class="anchor" id="autotoc_md1"></a>
Table of contents</h1>
<ul>
<li><a href="#Requirements">Requirements</a></li>
<li><a href="#Setup">Setup</a></li>
<li><a href="#Instructions">Instructions</a></li>
</ul>
<h1><a class="anchor" id="autotoc_md2"></a>
Requirements</h1>
<p>This code submission run in the Jupyter Notebook, so you may need to install Jupyter Notebook. Also, the code is in Python so you will need to use few Python's libraries/packages: numPy, pandas, TensorFlow, and Matplotib.</p>
<p>Note: if you are able to run the code in a different software/environment, you can skip the Setup section. You could install numPy, pandas, TensorFlow, and Matplotlib with with Pip.</p>
<h1><a class="anchor" id="autotoc_md3"></a>
Setup</h1>
<p>To run this project, install <a href="https://jupyter.org/">Jupyter Notebook</a>. If you have Pip installed in your environment, you could run and install it by entering:</p>
<div class="fragment"><div class="line">$ pip install jupyter</div>
</div><!-- fragment --><p>Once you get your Jupyter Notebook installed in your operating system, you can launch it by entering:</p>
<div class="fragment"><div class="line">$ jupyter notebook</div>
</div><!-- fragment --><p><img src="https://github.com/ck2860/CodeSubmissionS2/blob/master/screenshot/jupyternotebook.png?raw=true" alt="Jupyter Notebook Dashboard" class="inline"/></p>
<p>It will take you to the Notebook Dashboard. To create a notebook (the notebook is where you run code), you can click the "New" drop-down button on top-right then select "Python 3". Finally, you are in your first notebook then may run code.</p>
<p>numPy and Matplotlib are already installed in Jupyter notebook, you only need to install TensorFlow. Using the Anaconda Prompt, it can be done by entering:</p>
<div class="fragment"><div class="line">$ conda install -c conda-forge tensorflow</div>
</div><!-- fragment --><p>Note: It depends on your system. There are other commands that you can run with conda. Please read more about the <a href="https://anaconda.org/conda-forge/tensorflow">Tensorflow Installment</a>.</p>
<h1><a class="anchor" id="autotoc_md4"></a>
Instructions</h1>
<p>At first, you will need to download <a href="https://github.com/ck2860/CodeSubmissionS2/blob/master/data/Ads_Optimisation.csv">Ads Optimisation data</a>, which is already provided in the data folder. You will import the data set in the Notebook. The data set is obtained from <a href="https://www.kaggle.com/akram24/ads-ctr-optimisation">Kaggle</a>. You will use pandas and numpy as well.</p>
<p>Note: For this reinforcement learning, the data set can be used in online advertising to determine which is the best ad to show the user. It does not mean they would work with other bandit problems.</p>
<div class="fragment"><div class="line">import pandas as pd</div>
<div class="line">import numpy as np </div>
<div class="line">dir =&#39;your directory/&#39;</div>
<div class="line">file = &#39;Ads_Optimisation.csv&#39;</div>
<div class="line">adsDF = pd.read_csv(dir+file)</div>
<div class="line">adsDF.head(2)</div>
</div><!-- fragment --><p>Then you will need to find the probability of each ad. 10 ads will be split into 2 arrays. You will have two bandits.</p>
<div class="fragment"><div class="line">meansDF = adsDF.mean()</div>
<div class="line">newarr = np.array_split(meansDF, 2)</div>
<div class="line">data = np.array([newarr[0], newarr[1]])</div>
<div class="line">data = np.negative([newarr[0], newarr[1]])</div>
<div class="line">data</div>
</div><!-- fragment --><p>Your output data should look like this:</p>
<p><img src="https://github.com/ck2860/CodeSubmissionS2/blob/master/screenshot/meansData.png?raw=true" alt="Data Array" class="inline"/></p>
<p>Now, you can compile exploreFirst, epsilonDecreasing, and eGreedy strategies in the repo. Additionally, there are three different learning rates (0.001, 0.005, and 0.005) that you could test and compare the results. Because of the reinforcement learning and strategies, the evaluation results may be different.</p>
<p>Feel free to email me at <a href="#" onclick="location.href='mai'+'lto:'+'ck2'+'86'+'0@r'+'it'+'.ed'+'u'; return false;">ck286<span style="display: none;">.nosp@m.</span>0@ri<span style="display: none;">.nosp@m.</span>t.edu</a>.</p>
<p>Thanks for reading! </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.17
</small></address>
</body>
</html>
