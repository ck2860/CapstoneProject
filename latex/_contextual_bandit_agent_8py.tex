\hypertarget{_contextual_bandit_agent_8py}{}\doxysection{Contextual\+Bandit\+Agent.\+py File Reference}
\label{_contextual_bandit_agent_8py}\index{ContextualBanditAgent.py@{ContextualBanditAgent.py}}
\doxysubsection*{Classes}
\begin{DoxyCompactItemize}
\item 
class \mbox{\hyperlink{class_contextual_bandit_agent_1_1agent}{Contextual\+Bandit\+Agent.\+agent}}
\end{DoxyCompactItemize}
\doxysubsection*{Variables}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{_contextual_bandit_agent_8py_a0193412d8316fbe1c2c6a5c9e9a3df98}\label{_contextual_bandit_agent_8py_a0193412d8316fbe1c2c6a5c9e9a3df98}} 
{\bfseries Contextual\+Bandit\+Agent.\+category}
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
Documentation for Agent class This class sets up a contextual bandit agent via building a feed-\/forward in the network and training/updating the network. It would either return positive or negative reward. Positive reinforcement is a reward for picking the most optimal arm; negative reinforcement is a penalty for not picking the best arm. 